

Kubernetes API is used accessed by user via kubectl command
or Processes within the cluster using service account.

When a request reaches API it goes through these stages.


transport security:
API server servs on port 443.
API server will present a certificate.

certificate is self signed.
.kubeconfig will contain root certificate which is used to validate api server certificate


Authentication:
once tls is established, it moves to authentication.

cluster admin would have configured API server to run one or more authenticator modules.
client certifications - x509, token - jwt , password file.

multiple auth modules can be specified, each one is tried in sequence, until one of them succeeds.

if the requrest is not authenticated then, it is rejected with http status code 401.
if authenticated as user, then username, groupname info is taken and made available for authorization. 


x509 client certs.
client certificate authentication is enabled by passing --client-ca-file=ca.pem option to api server.
this is the ca to validate the client certificate presented to api server.

if client certificate is verified, CN is used as name for the request.
certificats organization field is used as group memberships.


kubeconfig: is like a database we can put multiple users and clusters and have context
that refer to things 

cluster:
certificate authority data:   - root certifcate to validate api server.
server: - address of api server. elb fronting api server.

kubernetes allows u to specify which root certificate to trust. 
for security in data center world, we dont use public ca that is appropriate for browser
since it is tightly controllered situation, 
for connection over tls in kubernetes cluster
provision private certifcate authority 
only trusting those certicate authorities.

as part of bootstrap process we create certificate authority 
here it is file based ca


user:
name: admin
client certifcate data:
client-key-data:  password to connecting to server 

we are establishing the mutual tls.
we know the root certificate to trust 
root certifcate has subject alternative name that i can be elb. 
we allocate the elb before actually creating the cluster.

we present this client certicate that says i am admin user.

kubectl get nodes -v=10   - gives verbose debug output.

https://prefetch.net/blog/2018/02/07/notes-from-episode-4-of-tgik-rbac/

openssl genrsa -output d.pem 2048

openssl req -new key d.pem -out d.csr -subj "/CN=user:d/O=app1/O=app2

cat d.csr | base64 | tr -d '\n'

creat csr
name: user:d
request: copy the base64 

kubectl create -f csr

kubectl certificate approve user-request-d

download the new signed public key from the csr resource

kubectl get csr
kubectl describe csr user-request-d

kubectl get csr user-request-d -o yaml
u can see certifcate in status

kubectl get csr user-request-d -o jsonpath='{.status.certificate}' | base64 -D > d.crt

now we have crt and private key - pem file.
put them into config file

kubectl config --kubeconfig=config-demo set-cluster development --server=https://localhost:6443 --insecure-skip-tls-verify
kubectl config --kubeconfig=config-demo set-credentials d --client-certificate=d.crt --client-key=d.pem
kubectl config --kubeconfig=config-demo set-context dev --cluster=development --namespace=user --user=d

kubectl config --kubeconfig=config-demo view

kubectl config --kubeconfig=config-demo use-context dev

export KUBECONFIG=./config-demo

kubectl run nginx2 --image=ngnix 

now we have authenticated the user, but failing authorization




Authorization:
authentication is who it is 
authorization is what they can do

rbac is back port of openshift which redhat is spear heading.

a request includes username of the request, the requested action, and the object affected by action.
the request is authorized if an existing policy declares that the user has the permission to complete 
the requested action.

kubernets supports multiple authorization modules ABAC mode, rbac mode and webhook mode.

ABAC is deprecated.

webhook - u have pass user, requested action to webhook, webhook might return whther they 
are allowed to do or not.


role based access control (rbac) is used regulate access based on roles of individual within
an enterprise.

there is 4 different modes in rbac

Role and ClusterRole
Rolebinding and clusterrolebindings

when we create objects in kubernetes we need to make decision whether these objects
needs to be in a namespace.

pods, services, deployment are all namespace objects, they need to be in a namespace.

nodes, pv are cluster objects. they are not in any namespace.

k get pods - this is default namespace.

k get pod -n default

k get pod -n kube-system

namespace are a way to curve objects.

csr is also an object in kubenetes which does not have a namespace.

k get nodes -o yaml | less - u see namespace as " "

these are cluster wide resources.

role are namespace resources and cluster role are cluster wide resources.

role is within a namespace 
cluserrole is for policy for entire cluster.

k get roles --all-namespaces

some are in public and kube-system namespaces.

k get clusterroles

we see bunch of controller, they run under their own role.
we see cluster-admin basic-user

if u scroll down in the docs we will see role descriptions

k get clusterroles system:basic-user -o yaml
we see
which objects are acting on, which verbs are allowed.

how we identify the resource is apigroup - is grouping the resources
resource we can narrow down to specific object

k get clusterroles admin -o yaml
we these resources we can do these verbs


rolebinding and clusterrolebindings 

clusterrollbings
allow this user do this thing across the cluster.

k create rolebinding d --clusterrole=admin --user=user:d --dry-run -o yaml

we are creating rolebinding it name is d 

k create rolebinding d --clusterrole=admin --user=user:d 
k get rolebinding

now u should get k get pod and create pod rights to user:d

create two windows 

create namespace and control what users are create what objects in what namespaces.

when we shared cluster with lot of users.

we can take the list of users and create namespace for each of users.
give them certificates or authentication 
like ldap or github can authenticate them in 

each of users we can give their own development namespace 
then we can use rbac to restrict who can actually do what with that namespace.

may we can give read access to everybody but write access to private namespace.

k create clusterrolebinding d-readonly --clusterrole=view --user=user:d

can read pods but not create pods 


refer to heptio rbac cheat sheet

service account

every namespace comes with sa 
kubectl get sa

k create namespace foo
k get sa -n foo -o yaml

- service accound default in foo namespace

k get sa --all-namespaces

for application we can give a private service account, robot identity 
the program can use to talk to api server.

this is automatically managed by system.

as rbac was turn on - default service account moved from root of cluster to zero privileges
on cluster

application should be using domain specific service account for that app
figure out what resources that realy need access to 
craft an rbac policy for that 
rbac policy could be role or rolebinding if it is actually dealing with stuff
in its own namespace
or clusterrole and clusterrolebinding if it is dealing with across namespace 

which is a good quick permissions workaround if less secure, is to grant admin access 
to the default service account for a particular namespace to that same application namespace. 
You can do this on a namespace by namespace basis.

Do this by creating a new RoleBinding. Replace the namespace varMyNamespace to give the 
default service account admin access to the namespace for a particular application:


kubectl create rolebinding varMyRoleBinding \
  --clusterrole=admin \
  --serviceaccount=varMyNamespace:default \
  --namespace=varMyNamespace

The last option to get around the new RBAC permissions without completely turning them off 
is to give the kube-system default service account admin access to the whole cluster.
 Most things that operate across the entire cluster run in kube-system. 
 This is a very broad-brushed approach, and not secure, 
 but it should get you past permission errors due to RBAC.

Do this by creating a new ClusterRoleBinding. This lets the default service account 
operate outside its namespace:

kubectl create clusterrolebinding varMyClusterRoleBinding \
  --clusterrole=cluster-admin \
  --serviceaccount=kube-system:default

http://docs.heptio.com/content/tutorials/rbac.html






