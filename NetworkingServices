Networking and services.

There are 4 distinct networking problems to solve:

each pod has IP in a flat shared networking namespace that has full communication with other
physical computers and containers across the network.

IP-per-pod creates a clean, backward-compatible model where pods can be treated much like VMs 
or physical hosts from the perspectives of port allocation, networking, naming, service discovery, 
load balancing, application configuration, and migration.


Container to container
All containers within a pod behave like applications on same host with regard to networking. 
container within the pod share the network namespace - including IP address and port space.
They can all reach each other’s ports on localhost. 

network namespace gets created first then docker container joins to namespace.

This also reduces friction for applications moving from the world of uncontainerized apps on 
physical or virtual hosts. People running application stacks together on the same host have already 
figured out how to make ports not conflict and have arranged for clients to find them.


The approach does reduce isolation between containers within a pod — ports could conflict
the premise of pods is that containers within a pod share some resources (volumes, cpu, ram, etc.)
and therefore expect and tolerate reduced isolation. 



export KUBECONFIG=~/

k get nodes
k get version
which kubectl - installed via homebrew

k run nginx --image=nginx --replicas=3

k get pods

kuble port-forward <podname> 8080:80

chrome: localhost:8080

k exec -ti <pod> -- /bin/bash
hostname

ifconfig 
- eth0

every single pod in kubernetes gets its own cluster private ip address seperate from the node it is running on.

k get pod -o wide
show ip addres of the node and ip address of pod.


pod to pod

since every pod gets its own ip address they can communicate with each other, without proxies and
translations.

pods can talk to each other using well known ports or using service discovery systems like dns-sd  
consul, 

When any container calls ioctl(SIOCGIFADDR) (get the address of an interface), 
it sees the same IP that any peer container would see them coming from — 
each pod has its own IP address that other pods can know. 

By making IP addresses and ports the same both inside and outside the pods, 
we create a NAT-less, flat address space. 

This would enable all existing naming/discovery mechanisms to work out of the box, 
including self-registration mechanisms and applications that distribute IP addresses.


kubectl exec -ti pod2 -- /bin/bash
curl pod2



host to pod communication

ssh to master
k get node
curl <podip>

there we are seeing we can communicated from cluster to pod, 
from different node to pod on different node.



pod to host communication

python -m SimpleHTTPServer 8000
bg
curl localhost:8000
curl <host ip address>:8000

k get pods
k exec -ti pod1 -- /bin/bash
curl <host ip address>:8000


we have full connectivity 
pod to pod
host to pod
pod to host


communicate from outside the cluster to pod inside the cluster.
this is done through service.

service combines the service and endpoint api

k expose deployment nginx --type=LoadBalancer --help

k expose deployment nginx --type=LoadBalancer --target-port=8080 --port=80

created a service object and point that to set to pods deployed by this deployment.

deployment dont know anything about service.

kubectl is looking at the deployment, takes the label and puts that to service. 

k expose deployment nginx --type=LoadBalancer --target-port=8080 --port=80 -o yaml --dry-run
point to selector

there is no reference to deployment.

k get svc nginx -o yaml 
point selector


service
- clusterip
- nodeport
- LoadBalancer
- external name

type of service is imp on how we are going to use the service.

service type = external name
use kubernetes service discovery, but point it to outside of cluster
externalname we have point to dns address
useful to connect inside the kubernets to outside.

service type = None - headless service

k expose deployment nginx --type=None --target-port=8080 --port=80 
k get svc nginx -o yaml

create a service object - with a selector 
it is named label query.
kubernets collects the information about the endpoints and puts in different ep api 

kubectl get ep nginx 

there are readiness probes, pods not ready to receive traffic are filtered out.
only ready pods show up on endpoints.



service type = clusterip
k expose deployment nginx --type=clusterip --target-port=8080 --port=80 
k get svc nginx -o yaml

cluster ip is assigned.
this is a seperate ip range than the pods are actually using.
this is a virtual ip 

for the life of the service this ip address will not change.
there is another component that is running on each node 
make this magic ip work

ssh to worker node:
k get pod -n kube-system
kubeproxy - mananged by daemonsets
runs on very node 


kubeproxy make the magic virtual ip work.
monitor services to find all the cluster ip 
go look at the buddy endpoint
configures ip tables 
such that any traffic going to cluster ip
gets randomly loadbalanced using ip tables across all of the endpoints.

sudo -s
sudo apt-get update && apt-get install iptables

iptable -L
ip tables are managed by calico 

iptables-save | less 
calico would have installed routes

there will be kubernetes service portals 
KUBE-SERVICES 
we see cluster ip 
any packet comming to this ip address, send it down to this chain 
this chain based on random probability will redirect to one of the backend.
last one is default unconditional jump.


than ends up doing nat. dnat to actual destination pod that backing the service.

this is all managed and configured by kubernetes proxy 


dns is another extension that is built on top of kubernetes that watches all the services
undestands the names to services and the endpoints and then creates dns records.

kubectl exec -ti pod1 -- /bin/bash
nslookup <servicename>
return clusterip

cluster.local - cluster name
service 
namespace - default - i want to see in my own namespace, if u want to look across namespace, u can do that.
dns will resolve it.


till now was for on cluster communication

communication to outside the cluster


service type = Nodeport
k expose deployment nginx --type=Nodeport --target-port=8080 --port=80

k get svc nginx -o yaml
type = nodeport
ports: nodeport: 32000
we are dynamically assigning host ports.

this bridges outside the cluser to inside the cluster 

nodeport will redirect the traffic to service.

ssh to node 
export KUBECONFIG

k get pods
curl nodeip:port

this is way of bridging from outside the cluster to inside the cluster 
nodeport -> service ip -> magic happens in iptables -> redirect to pod



service type = LoadBalancer

k expose deployment nginx --type=LoadBalancer --target-port=8080 --port=80
k get svc nginx -o yaml

this will work is cluster is in GC, aws, openstack configuration 
kubernetes will go out and creates an elb for you
and configures the elb to point at all the worker nodes of your cluster 
at the nodeport

chrome elb  - wait for elb to become inservice.
refresh we end up with different host.

this service is exposed to world

elb -> nodeport -> clusterip -> iptables -> dest pod 
there is some hoping around different nodes

there is health checks the nodes that are not running pod, reply not to bother them.
send to only nodes running the pod.

this will be much more direct network path.



























